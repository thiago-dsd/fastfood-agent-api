import logging

from datetime import datetime
from typing import Literal, cast

from langchain.prompts import SystemMessagePromptTemplate
from langchain_core.language_models.chat_models import BaseChatModel
from langchain_core.messages import AIMessage, HumanMessage, SystemMessage
from langchain_core.runnables import RunnableConfig, RunnableLambda, RunnableSerializable
from langgraph.checkpoint.memory import MemorySaver
from langgraph.graph import END, MessagesState, StateGraph
from langgraph.types import interrupt
from pydantic import BaseModel, Field

from core import get_model, settings

logging.basicConfig(level=logging.INFO, format="%(asctime)s - %(levelname)s - %(message)s")

class AgentState(MessagesState, total=False):
    """Estado do agente para o FastFood."""
    order_details: str
    capture_order_state: Literal["order", "end", "conversation"]
    confirm_order_state: Literal["confirmed", "redirect_to_capture"]

def wrap_model(model: BaseChatModel, system_prompt: SystemMessage) -> RunnableSerializable[AgentState, AIMessage]:
    """Encapsula o modelo com um prompt de sistema."""
    preprocessor = RunnableLambda(
        lambda state: [system_prompt] + state["messages"],
        name="StateModifier",
    )
    return preprocessor | model


order_capture_prompt = SystemMessagePromptTemplate.from_template("""
Voc√™ √© um assistente de pedidos do FastFood. Sua tarefa √© extrair os detalhes do pedido do usu√°rio a partir do hist√≥rico de conversas.
Extraia os itens, quantidades e personaliza√ß√µes mencionados pelo usu√°rio.
Se n√£o houver detalhes suficientes, explique o que est√° faltando.
""") 

confirmation_prompt = SystemMessagePromptTemplate.from_template("""
Voc√™ deve confirmar os detalhes do pedido com o usu√°rio.
Se o usu√°rio confirmar, o pedido ser√° finalizado.
Se o usu√°rio quiser corrigir algo, pe√ßa para ele fornecer os detalhes atualizados.
Seja paciente e educado!
""")

async def capture_order(state: AgentState, config: RunnableConfig) -> AgentState:
    """Este n√≥ captura o pedido do usu√°rio ou redireciona o fluxo com base na inten√ß√£o do usu√°rio."""
    logging.info("CAPTURE ORDER")
    m = get_model(config["configurable"].get("model", settings.DEFAULT_MODEL))

    # Verifica se o usu√°rio est√° interessado em fazer um pedido ou apenas conversando
    intent_prompt = SystemMessagePromptTemplate.from_template("""
    Analise a conversa do usu√°rio e determine se ele est√° interessado em fazer um pedido ou apenas conversando.
    Responda com:
    - "order" se o usu√°rio estiver interessado em fazer um pedido.
    - "conversation" se o usu√°rio estiver falando sobre assuntos que n√£o envolvam pedido ou
    estiver solicitando informa√ß√µes sobre card√°pio.
    - "end" se o usu√°rio quiser finalizar a intera√ß√£o.
    Hist√≥rico de conversa: {messages}
    """)

    intent_model = wrap_model(m, intent_prompt.format(messages=state["messages"]))
    intent_response = await intent_model.ainvoke(state, config)
    intent = intent_response.content.strip().lower()

    logging.info(f"Inten√ß√£o detectada: {intent}")

    if intent == "order":
        order_capture_model = wrap_model(m, order_capture_prompt.format())
        response = await order_capture_model.ainvoke(state, config)
        order_details = response.content.strip()

        state["messages"].append(AIMessage("Detalhes do pedido capturados com sucesso!"))
        return {
            "order_details": order_details,
            "capture_order_state": "order",
        }
    elif intent == "end":
        state["messages"].append(AIMessage("Obrigado por interagir conosco! At√© a pr√≥xima. üëã"))
        return {
            "capture_order_state": "end",
        }
    else:
        state["messages"].append(AIMessage("Como posso ajudar voc√™ hoje?"))
        return {
            "capture_order_state": "conversation",
        }
    
async def handle_conversation(state: AgentState, config: RunnableConfig) -> AgentState:
    """Este n√≥ lida com conversas gen√©ricas, como perguntas sobre o card√°pio ou informa√ß√µes gerais."""
    logging.info("HANDLE CONVERSATION")
    m = get_model(config["configurable"].get("model", settings.DEFAULT_MODEL))

    # Pergunta ao usu√°rio sobre o que ele gostaria de saber
    conversation_prompt = SystemMessagePromptTemplate.from_template("""
    Voc√™ √© um assistente de atendimento ao cliente do FastFood.
    Responda √†s perguntas do usu√°rio de forma educada e √∫til.
    Se o usu√°rio quiser fazer um pedido, pe√ßa para ele fornecer os detalhes.
    Hist√≥rico de conversa: {messages}
    """)

    conversation_model = wrap_model(m, conversation_prompt.format(messages=state["messages"]))
    response = await conversation_model.ainvoke(state, config)
    response_message = response.content.strip()

    state["messages"].append(AIMessage(response_message))
    return state

async def confirm_order(state: AgentState, config: RunnableConfig) -> AgentState:
    """Confirma os detalhes do pedido com o usu√°rio. Interpreta a inten√ß√£o do usu√°rio."""
    logging.info("CONFIRM ORDER")
    m = get_model(config["configurable"].get("model", settings.DEFAULT_MODEL))
    model_runnable = wrap_model(m, confirmation_prompt.format())

    # Pergunta ao usu√°rio de forma mais natural
    confirm_input = interrupt(
        f"Seu pedido:\n{state.get('order_details')}\n\n"
        "Por favor, confirme se est√° tudo certo ou se deseja fazer alguma altera√ß√£o."
    )
    state["messages"].append(HumanMessage(confirm_input))

    # Captura a resposta do usu√°rio
    user_response = confirm_input

    logging.info(f"user_response: {user_response}")

    # Usa o modelo de linguagem para interpretar a inten√ß√£o do usu√°rio
    intent_prompt = SystemMessagePromptTemplate.from_template("""
    Fa√ßa uma an√°lise da RespostaBase do usu√°rio e retorne:
    - "confirm" caso ele diga de forma expl√≠cita que deseja confirmar/finalizar.
    - "change" caso ele comente sobre adicionar novos itens ou alterar os itens j√° existentes.
    RespostaBase: {user_response}
    """)
    intent_model = wrap_model(m, intent_prompt.format(user_response=user_response))
    intent_response = await intent_model.ainvoke(state, config)
    intent = intent_response.content.strip().lower()

    logging.info(f"Inten√ß√£o detectada: {intent}")

    # Decide o pr√≥ximo passo com base na inten√ß√£o detectada
    if intent == "confirm":
        state["messages"].append(AIMessage("Pedido confirmado! ‚úÖ"))
        return {"confirm_order_state": "confirmed"}  # Atualizado
    elif intent == "change":
        state["messages"].append(AIMessage("Certo! Vamos ajustar seu pedido. ‚úèÔ∏è"))
        return {"confirm_order_state": "redirect_to_capture"}  # Atualizado
    else:
        state["messages"].append(AIMessage("Desculpe, n√£o entendi. Poderia repetir, por favor?"))
        return {"confirm_order_state": None}  # Ou outro valor padr√£o, se necess√°rio

async def register_order(state: AgentState, config: RunnableConfig) -> AgentState:
    """Agradece pelo pedido e finaliza o fluxo."""
    logging.info("REGISTER ORDER")

    final_message = (
        f"‚úÖ Pedido registrado com sucesso!\n"
        "Agradecemos sua prefer√™ncia! Seu pedido j√° est√° a caminho. üöö\n"
        "Se quiser fazer outro pedido, √© s√≥ mandar uma mensagem aqui no chat!"
    )

    logging.info("adicionando final message")
    state["messages"].append(AIMessage(
        content=final_message,
        response_metadata={
            "order_details": {
                "description": state.get("order_details"),
            }
        }
    ))

    return state

def check_confirmation(state: AgentState) -> Literal["register_order", "capture_order", "confirm_order"]:
    """
    Verifica o estado atual e decide o pr√≥ximo n√≥.
    - Se o pedido foi confirmado, redireciona para "register_order".
    - Se o usu√°rio quer alterar o pedido, redireciona para "capture_order".
    - Caso contr√°rio, repete o n√≥ "confirm_order".
    """
    if state.get("confirm_order_state") == "confirmed":
        return "register_order"
    elif state.get("confirm_order_state") == "redirect_to_capture":
        return "capture_order"
    else:
        return "confirm_order"

def check_capture(state: AgentState) -> Literal["confirm_order", "handle_conversation", "END"]:
    """
    Verifica o estado atual e decide o pr√≥ximo n√≥.
    - Se o usu√°rio estiver fazendo um pedido, redireciona para "confirm_order".
    - Se o usu√°rio estiver apenas conversando, redireciona para "handle_conversation".
    - Se o usu√°rio quiser finalizar, redireciona para "END".
    """
    if state.get("capture_order_state") == "order":
        return "confirm_order"
    elif state.get("capture_order_state") == "conversation":
        return "handle_conversation"
    elif state.get("capture_order_state") == "end":
        return END

agent = StateGraph(AgentState)
agent.add_node("capture_order", capture_order)
agent.add_node("handle_conversation", handle_conversation)
agent.add_node("confirm_order", confirm_order)
agent.add_node("register_order", register_order)

agent.set_entry_point("capture_order")

agent.add_edge("register_order", END)
# agent.add_edge("handle_conversation", "capture_order")

agent.add_conditional_edges(
    "capture_order",
    check_capture,
    {
        "confirm_order": "confirm_order", 
        "handle_conversation": "handle_conversation",
        END: END
    },
)

agent.add_conditional_edges(
    "confirm_order",
    check_confirmation,
    {
        "register_order": "register_order",
        "capture_order": "capture_order",
        "confirm_order": "confirm_order", 
    },
)


fastfood_agent = agent.compile(checkpointer=MemorySaver())
fastfood_agent.name = "fastfood-agent"